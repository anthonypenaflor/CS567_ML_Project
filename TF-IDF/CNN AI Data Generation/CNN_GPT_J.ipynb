{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EODBl8IWrMCa",
    "outputId": "0d3ebf99-02ca-47ae-88d1-462c790ff8a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.40.1)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
      "Requirement already satisfied: openpyxl in /usr/local/lib/python3.10/dist-packages (3.1.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl) (1.1.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.11.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n"
     ]
    }
   ],
   "source": [
    "pip install transformers pandas openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IlRktdyGrvYk",
    "outputId": "9571c370-f16f-479f-8248-70765f4ce851"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "import numpy as np\n",
    "\n",
    "# Mount Google Drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Function to set up the generator pipeline\n",
    "def setup_generator(model_name=\"EleutherAI/gpt-j-6B\"):\n",
    "    generator = pipeline('text-generation', model=model_name)\n",
    "    return generator\n",
    "\n",
    "# Set up text generation model\n",
    "generator = setup_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FztqSKgzIqrL",
    "outputId": "3166708c-6527-4508-dd5d-4f593ec959ff"
   },
   "outputs": [],
   "source": [
    "# Final code being used\n",
    "\n",
    "# Function to generate text based on prompts\n",
    "def generate_articles(generator, prompts, max_length=1200):\n",
    "    articles = []\n",
    "    count = 0\n",
    "    for prompt in prompts:\n",
    "        count += 1\n",
    "        print(count , f\"Generating article for prompt: {prompt[:50]}...\")  # Print the beginning of the prompt for clarity\n",
    "        generated = generator(prompt, max_length=max_length, num_return_sequences=1)\n",
    "        # Append both the prompt (first 30 words) and the generated text\n",
    "        articles.append((prompt, generated[0]['generated_text']))\n",
    "    return articles\n",
    "\n",
    "# Function to extract the first 30 tokens\n",
    "def get_first_30_tokens(texts, generator):\n",
    "    tokenizer = generator.tokenizer\n",
    "    prompts = []\n",
    "    for text in texts:\n",
    "        tokens = tokenizer.tokenize(text)\n",
    "        # Get the first 30 tokens and convert to string\n",
    "        prompt = tokenizer.convert_tokens_to_string(tokens[:30])\n",
    "        prompts.append(prompt)\n",
    "    return prompts\n",
    "\n",
    "# Main function to load data, generate articles, and save them\n",
    "def main(input_file, output_file):\n",
    "    # Load data\n",
    "    df = pd.read_excel(input_file)\n",
    "    if len(df) > 130:\n",
    "        df = df.sample(n=130)  # Randomly sample 130 articles\n",
    "    texts = df['text'].tolist()\n",
    "\n",
    "    # Extract the first 30 tokens as prompts\n",
    "    prompts = get_first_30_tokens(texts, generator)\n",
    "\n",
    "    # Generate articles\n",
    "    articles = generate_articles(generator, prompts)\n",
    "\n",
    "    # Save generated articles to a new DataFrame and then to Excel\n",
    "    articles_df = pd.DataFrame(articles, columns=['Prompt', 'Generated Article'])\n",
    "    articles_df.to_excel(output_file, index=False)\n",
    "    print(f\"Generated articles saved to {output_file}\")\n",
    "\n",
    "input_file = '/content/drive/My Drive/ML Project data/test_CNN_Article - Cleaned - Copy2.xlsx'\n",
    "output_file = '/content/drive/My Drive/ML Project data/output_file_GPT-J.xlsx'\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(input_file, output_file)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
